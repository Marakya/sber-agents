# 03-aidd — Telegram LLM Bot (мини-проект)

Легковесный Telegram-бот с интеграцией LLM через OpenRouter. Проект реализует пошаговую итерационную разработку (итерации 1–4 завершены):

- Итерация 1 — базовый эхо-бот (готов)
- Итерация 2 — интеграция с LLM через OpenRouter (готов)
- Итерация 3 — история диалога в памяти (готов)
- Итерация 4 — финальная полировка: обработка edge-cases, улучшенные ошибки, ограничения истории (готов)

## Возможности

- Общение с LLM в естественном диалоге
- Сохранение контекста беседы (в памяти процесса)
- Поддержка нескольких пользователей одновременно
- Асинхронная обработка запросов
- Простая настройка через переменные окружения

## Требования

- Python 3.11+
- [uv](https://github.com/astral-sh/uv) — менеджер зависимостей, используемый в Makefile

## Быстрый старт (локально)

Репозиторий содержит Makefile с командами `install` и `run`. На большинстве машин последовательность будет такая:

1) Создайте виртуальное окружение (если ещё нет):

```powershell
python -m venv .venv
```

2) Активируйте виртуальное окружение.

- В PowerShell (Windows):
```powershell
.\.venv\Scripts\Activate.ps1
```

- В классическом cmd.exe (Windows):
```cmd
.\.venv\Scripts\activate.bat
```

- В Git Bash / WSL / bash:
```bash
source .venv/Scripts/activate
```

3) Установите зависимости через Makefile (в Makefile `install` вызывает `uv sync`):

```bash
make install
```

Примечание: `uv` может создавать и управлять lock-файлами; если вы не используете `uv`, установите зависимости напрямую через `pip install -r requirements.txt` (при наличии) или используйте `pip install .`.

4) Настройте переменные окружения:

```bash
cp .env.example .env
# затем откройте .env и заполните значения
```

Основные переменные (в `.env`):

- `TELEGRAM_TOKEN` — токен бота от @BotFather (обязательно)
- `OPENAI_API_KEY` — API ключ для OpenRouter (обязательно)
- `OPENAI_BASE_URL` — URL OpenRouter API (по умолчанию: https://openrouter.ai/api/v1)
- `MODEL` — модель LLM (пример: openai/gpt-oss-20b:free)
- `SYSTEM_PROMPT` — системный промпт / инструкция для LLM

5) Запустите бота:

```bash
make run
```

Внутри Makefile команда `run` использует `uv run python -m src.bot` — это запускает модуль `src.bot` с корректными путями пакетов.

Если хотите запускать напрямую без Makefile:

```bash
python -m src.bot
```

## Использование бота

- `/start` — начать новый диалог (сбросить историю)

Примеры:

Пользователь: "Меня зовут Иван"

Пользователь: "Как меня зовут?" → Бот: "Вас зовут Иван."

(История диалога сохраняется в памяти процесса — при перезапуске бота история теряется.)

## Ограничения и поведение

- Бот принимает только текстовые сообщения; мультимедиа и стикеры игнорируются
- Максимальная длина пользовательского сообщения: 4000 символов
- История диалога хранится в памяти (ограничение по количеству последних диалогов, чтобы не раздувать запросы)
- При ошибках LLM пользователю выводятся дружелюбные сообщения с рекомендациями (повторить попытку, начать /start)

## Структура проекта

```
03-aidd/
├── docs/                  # Документация проекта
│   ├── adrs/             # Architecture Decision Records
│   ├── idea.md           # Изначальная идея проекта
│   ├── vision.md         # Техническое видение
│   ├── tasklist.md       # План итераций и прогресс
│   ├── conventions.md    # Соглашения по коду
│   └── workflow.md       # Рабочий процесс
├── screenshots/          # Скриншоты для документации
├── src/                  # Исходный код
│   ├── bot.py           # Точка входа, инициализация aiogram
│   ├── config.py        # Загрузка конфигурации из .env
│   ├── handlers.py      # Обработчики сообщений и история
│   └── llm.py           # Интеграция с OpenRouter API
├── .env                 # Локальные переменные окружения (не в git)
├── .env.example         # Пример переменных окружения
├── .gitignore          # Исключения для git
├── Makefile            # Команды: install, run
├── pyproject.toml      # Зависимости и метаданные
├── uv.lock             # Lock-файл зависимостей
└── README.md           # Основная документация
```

## Разработка и тестирование

- Локальный запуск: `make run` (после активации `.venv` и `make install`)
- Рекомендуется проверять логи для отладки (файловое/консольное логирование настроено в проекте)
- Unit-тесты пока не покрывают модуль LLM; можно добавить тесты для парсинга/малых частей логики

## Следующие шаги / идеи

- Добавить персистентное хранилище истории (Redis) для состояния между перезапусками
- Добавить CI (lint, tests) и Dockerfile для контейнеризации
- Расширить обработку пользовательских данных и безопасность (валидация, rate-limiting)

## Лицензия

MIT

