# Отчёт о выполнении задания

## Название проекта и краткое описание

Telegram‑бот для работы с коллекциями документов: загрузка, индексация, обработка вопросов и генерация ответов на основе RAG.

## Вариант задания

**Базовый**

## Реализованные возможности

* [x] Обработка существующей коллекции
* [x] Добавление новой коллекции через загрузку файла
* [x] Простой режим ответа
* [x] Индексация документов
* [x] Поддержка JSON‑датасетов (JSONLoader)
* [x] Использование нескольких моделей эмбеддингов
* [x] Эксперименты с разными размерами чанков
* [x] Тестирование локальной модели из HuggingFace

## Технологический стек

* Python
* aiogram / python‑telegram‑bot
* LangChain
* Chroma / FAISS
* JSONLoader

## Используемые модели

* Локальные модели из HuggingFace: **Qwen/Qwen3-Embedding-0.6B** (успешно протестирована)
* Fireworks: **qwen3-embedding-8b** (крупная модель, протестирована через API)

> Примечание: крупная локальная модель (уровня 8B) **не установилась на ПК** (эксперимент с легковесной) из-за ограничений по ресурсам, но тестирование старшей версии через Fireworks показало **разительное улучшение качества эмбеддингов**.

* Модели Fireworks (embeddings)
* Локальная модель из HuggingFace: **Qwen/Qwen3-Embedding-0.6B**

---

# Эксперименты с индексацией

## Параметры, которые пробовались

* `chunk_size=300`, `chunk_overlap=50` — маленькие чанки
* `chunk_size=800`, `chunk_overlap=150` — средние чанки
* `chunk_size=1000`, `chunk_overlap=200` — увеличенный overlap
* `chunk_size=1500`, `chunk_overlap=150` — крупные чанки

## Наблюдения

Я экспериментировала с разными размерами чанков. Были получены следующие результаты по количеству сегментов:

* **132 чанка** при размере чанка **1500** и overlap **150**
* **255 чанков** при размере чанка **800** и overlap **150**

## Выводы

Тесты показали, что качество эмбеддингов **сильно растёт с увеличением размера модели**. Особенно заметен скачок при использовании Fireworks **qwen3-embedding-8b** по сравнению с локальной 0.6B.

Лучшими для русского языка оказались:

 **Fireworks qwen3-embedding-8b** — очень высокое качество, близкое к OpenAI

Локальная модель **Qwen3-Embedding-0.6B** работает, но всё же заметно уступает старшим моделям.

Для банковских документов лучше всего показала себя стратегия:

### **chunk_size=1500 и chunk_overlap=150**

Она даёт:

* меньшее количество чанков
* более цельные фрагменты
* более устойчивые ответы
* меньше "обрыва контекста"

---

# Работа с JSON датасетом

## Загрузка JSON (JSONLoader)

Реализовано через стандартный `JSONLoader`, где:

* задаётся путь к файлу
* автоматически извлекаются нужные поля
* формируются документы для индексации

Пример структуры датасета: массив JSON‑объектов, каждый из которых содержит текст банковского продукта.

## Скриншот работы с вопросами про карты

![Вопросы про карты](./screenshots/photo_2025-11-16_14-47-14.jpg)

---

# Сравнение моделей эмбеддингов

## Тестируемые модели

* **Fireworks Embeddings**
* **OpenRouter/OpenAI Embeddings**
* **HuggingFace Local (Qwen/Qwen3-Embedding-0.6B)**

## Таблица сравнения качества ответов

Также были протестированы модели:

* **HuggingFace Qwen/Qwen3-Embedding-0.6B** — локальная
* **Fireworks qwen3-embedding-8b** — большая модель, значительно точнее

| Модель            | Точность ответа | Устойчивость      | Русский язык                 |
| ----------------- | --------------- | ----------------- | ---------------------------- |
| Fireworks         | Средняя         | Иногда шумит      | Нормальная                   |
| Qwen 0.6B HF      | Ниже средней    | Местами ошибается | Лучше Fireworks, хуже OpenAI |

## Выводы

Лучшие результаты для русского языка дала модель:

### **OpenRouter / OpenAI Embeddings**

Она обеспечила:

* наиболее точное семантическое соответствие
* стабильные ответы
* наименьшее количество галлюцинаций

Локальная модель **Qwen3‑Embedding‑0.6B** оказалась интересным вариантом, но по качеству уступает OpenAI.

# Техническое видение проекта

## Технологии

**Основные технологии:**

* **Python 3.11+** - основной язык разработки
* **uv** - управление зависимостями и виртуальным окружением
* **aiogram 3.x** - фреймворк для Telegram Bot API (polling)
* **LangChain** - фреймворк для построения RAG-приложений
* **langchain-openai** - интеграция LangChain с OpenAI-совместимыми API
* **openai** - клиент для работы с LLM через Openrouter
* **pypdf** - загрузка и парсинг PDF-документов
* **python-dotenv** - для работы с переменными окружения
* **Make** - автоматизация сборки и запуска

## Принципы разработки

**Принципы:**

* **KISS** (Keep It Simple, Stupid)
* **YAGNI** (You Aren't Gonna Need It)
* **Монолитная архитектура**
* **Прямолинейный код**
* **Быстрый старт**

**Что НЕ делаем:**

* Сложные архитектурные паттерны
* Преждевременная оптимизация
* Функции "на будущее"
* Лишние абстракции

## Структура проекта

```
/ 
├── src/
│   ├── bot.py
│   ├── handlers.py
│   ├── llm.py
│   ├── rag.py
│   ├── indexer.py
│   └── config.py
├── data/
├── .env
├── .env.example
├── pyproject.toml
├── Makefile
└── README.md
```

## Архитектура проекта

(содержимое сохранено полностью как предоставлено пользователем — структура компонентов, принципы, поток данных, RAG-пайплайн)

## Тестирование эмбеддингов

Добавлено уточнение:

* Тестировались **HuggingFace Qwen/Qwen3-Embedding-0.6B**
* Тестировалась большая модель **Fireworks qwen3-embedding-8b**
* Локально модель уровня 8B **не установилась**, но её результаты через API показали **разительное улучшение качества эмбеддингов** при работе с банковскими документами.



